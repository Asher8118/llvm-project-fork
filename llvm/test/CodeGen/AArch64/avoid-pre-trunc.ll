; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 4
; RUN: llc -mtriple=aarch64 < %s | FileCheck %s

define i32 @lower_lshr(<4 x i32> %a, <4 x i32> %b, <4 x i32> %c, <4 x i32> %d, <4 x i32> %e, <4 x i32> %f, <4 x i32> %g, <4 x i32> %h) {
; CHECK-LABEL: lower_lshr:
; CHECK:       // %bb.0:
; CHECK-NEXT:    addv s16, v0.4s
; CHECK-NEXT:    addv s0, v1.4s
; CHECK-NEXT:    addv s1, v2.4s
; CHECK-NEXT:    addv s3, v3.4s
; CHECK-NEXT:    addv s4, v4.4s
; CHECK-NEXT:    addv s5, v5.4s
; CHECK-NEXT:    addv s6, v6.4s
; CHECK-NEXT:    addv s7, v7.4s
; CHECK-NEXT:    mov v2.16b, v16.16b
; CHECK-NEXT:    mov v16.h[1], v0.h[0]
; CHECK-NEXT:    mov v17.16b, v4.16b
; CHECK-NEXT:    mov v2.s[1], v0.s[0]
; CHECK-NEXT:    mov v16.h[2], v1.h[0]
; CHECK-NEXT:    mov v17.s[1], v5.s[0]
; CHECK-NEXT:    mov v2.s[2], v1.s[0]
; CHECK-NEXT:    mov v16.h[3], v3.h[0]
; CHECK-NEXT:    mov v17.s[2], v6.s[0]
; CHECK-NEXT:    mov v2.s[3], v3.s[0]
; CHECK-NEXT:    mov v16.h[4], v4.h[0]
; CHECK-NEXT:    mov v17.s[3], v7.s[0]
; CHECK-NEXT:    mov v16.h[5], v5.h[0]
; CHECK-NEXT:    uzp2 v2.8h, v2.8h, v17.8h
; CHECK-NEXT:    mov v16.h[6], v6.h[0]
; CHECK-NEXT:    mov v16.h[7], v7.h[0]
; CHECK-NEXT:    uhadd v2.8h, v16.8h, v2.8h
; CHECK-NEXT:    uaddlv s2, v2.8h
; CHECK-NEXT:    fmov w0, s2
; CHECK-NEXT:    ret
  %l87  = tail call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %a)
  %l174 = tail call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %b)
  %l257 = tail call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %c)
  %l340 = tail call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %d)
  %l427 = tail call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %e)
  %l514 = tail call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %f)
  %l597 = tail call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %g)
  %l680 = tail call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %h)
  %l681 = insertelement <8 x i32> poison, i32 %l87, i32 0
  %l682 = insertelement <8 x i32> %l681, i32 %l174, i32 1
  %l683 = insertelement <8 x i32> %l682, i32 %l257, i32 2
  %l684 = insertelement <8 x i32> %l683, i32 %l340, i32 3
  %l685 = insertelement <8 x i32> %l684, i32 %l427, i32 4
  %l686 = insertelement <8 x i32> %l685, i32 %l514, i32 5
  %l687 = insertelement <8 x i32> %l686, i32 %l597, i32 6
  %l688 = insertelement <8 x i32> %l687, i32 %l680, i32 7
  %l689 = and <8 x i32> %l688, <i32 65535, i32 65535, i32 65535, i32 65535, i32 65535, i32 65535, i32 65535, i32 65535>
  %l690 = lshr <8 x i32> %l688, <i32 16, i32 16, i32 16, i32 16, i32 16, i32 16, i32 16, i32 16>
  %l691 = add nuw nsw <8 x i32> %l689, %l690
  %l692 = lshr <8 x i32> %l691, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %l693 = call i32 @llvm.vector.reduce.add.v8i32(<8 x i32> %l692)
  ret i32 %l693
}

define <8 x i16> @lower_trunc(i32 %a, i32 %b, i32 %c, i32 %d, i32 %e, i32 %f, i32 %g, i32 %h) {
; CHECK-LABEL: lower_trunc:
; CHECK:       // %bb.0:
; CHECK-NEXT:    fmov s0, w0
; CHECK-NEXT:    fmov s1, w0
; CHECK-NEXT:    fmov s2, w4
; CHECK-NEXT:    mov v0.h[1], w1
; CHECK-NEXT:    mov v1.s[1], w1
; CHECK-NEXT:    mov v2.s[1], w5
; CHECK-NEXT:    mov v0.h[2], w2
; CHECK-NEXT:    mov v1.s[2], w2
; CHECK-NEXT:    mov v2.s[2], w6
; CHECK-NEXT:    mov v0.h[3], w3
; CHECK-NEXT:    mov v1.s[3], w3
; CHECK-NEXT:    mov v2.s[3], w7
; CHECK-NEXT:    mov v0.h[4], w4
; CHECK-NEXT:    add v2.4s, v2.4s, v2.4s
; CHECK-NEXT:    add v1.4s, v1.4s, v1.4s
; CHECK-NEXT:    mov v0.h[5], w5
; CHECK-NEXT:    uzp1 v1.8h, v1.8h, v2.8h
; CHECK-NEXT:    mov v0.h[6], w6
; CHECK-NEXT:    mov v0.h[7], w7
; CHECK-NEXT:    eor v0.16b, v0.16b, v1.16b
; CHECK-NEXT:    ret
  %a1 = insertelement <8 x i32> poison, i32 %a, i32 0
  %b1 = insertelement <8 x i32> %a1, i32 %b, i32 1
  %c1 = insertelement <8 x i32> %b1, i32 %c, i32 2
  %d1 = insertelement <8 x i32> %c1, i32 %d, i32 3
  %e1 = insertelement <8 x i32> %d1, i32 %e, i32 4
  %f1 = insertelement <8 x i32> %e1, i32 %f, i32 5
  %g1 = insertelement <8 x i32> %f1, i32 %g, i32 6
  %h1 = insertelement <8 x i32> %g1, i32 %h, i32 7
  %t = trunc <8 x i32> %h1 to <8 x i16>
  %s = add <8 x i32> %h1, %h1
  %t2 = trunc <8 x i32> %s to <8 x i16>
  %o = xor <8 x i16> %t, %t2
  ret <8 x i16> %o
}

declare i32 @llvm.vector.reduce.add.v4i32(<4 x i32>)
declare i32 @llvm.vector.reduce.add.v8i32(<8 x i32>)
